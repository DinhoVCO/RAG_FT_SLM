{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2511ce81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "SSL_CERT_FILE2 = os.getenv('SSL_CERT_FILE2', None)\n",
    "os.environ['SSL_CERT_FILE'] = SSL_CERT_FILE2\n",
    "AZURE_OPENAI_API_KEY = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "OPENAI_API_VERSION = os.getenv('OPENAI_API_VERSION')\n",
    "MODELS_STR = os.getenv('MODELS')\n",
    "MODELS = json.loads(MODELS_STR)\n",
    "\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = AZURE_OPENAI_API_KEY\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = AZURE_OPENAI_ENDPOINT\n",
    "os.environ[\"OPENAI_API_VERSION\"] = OPENAI_API_VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dc2fa8",
   "metadata": {},
   "source": [
    "## OpenAI answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3f08c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts.prompt_for_inference import prompt_for_inference\n",
    "from utils.datasets_splits import load_dataset_splits\n",
    "import openai\n",
    "import csv\n",
    "import os\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1c36185",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.AzureOpenAI(\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=OPENAI_API_VERSION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fe67daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import openai\n",
    "import os\n",
    "import csv\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "def answer_batch(dataset_name, dataset: Dataset, CSV_FILE, max_tokens=3):\n",
    "    ids_existentes = set()\n",
    "    ultimo_id = 0\n",
    "\n",
    "    # Verificar si ya existe el archivo\n",
    "    file_exists = os.path.exists(CSV_FILE)\n",
    "\n",
    "    # Si existe, cargar los IDs existentes\n",
    "    if file_exists:\n",
    "        with open(CSV_FILE, newline='', encoding='utf-8') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            for row in reader:\n",
    "                ids_existentes.add(int(row[\"id\"]))\n",
    "                ultimo_id = max(ultimo_id, int(row[\"id\"]))\n",
    "\n",
    "    # Crear el directorio si no existe\n",
    "    os.makedirs(os.path.dirname(CSV_FILE), exist_ok=True)\n",
    "\n",
    "    for i in tqdm(range(len(dataset)), desc=\"Generating responses\"):\n",
    "        if i + 1 in ids_existentes:\n",
    "            continue  # Ya procesado\n",
    "\n",
    "        final_prompt = prompt_for_inference(dataset_name, dataset[i])\n",
    "\n",
    "        # Intentar generar respuesta y manejar el RateLimitError\n",
    "        while True:\n",
    "            try:\n",
    "                chat_completion = client.chat.completions.create(\n",
    "                    model=MODELS[\"gpt-3.5-turbo\"],\n",
    "                    messages=[{\"role\": \"user\", \"content\": final_prompt}],\n",
    "                    max_tokens=max_tokens\n",
    "                )\n",
    "                respuesta = chat_completion.choices[0].message.content.strip()\n",
    "                break  # Si la solicitud fue exitosa, salimos del bucle\n",
    "\n",
    "            except openai.RateLimitError as e:\n",
    "                # Intentar extraer \"Try again in X seconds\" del mensaje\n",
    "                try:\n",
    "                    match = re.search(r'\"retryAfter\":\\s*\"(\\d+)\"', str(e))\n",
    "                    retry_after = int(match.group(1)) if match else 40  # fallback a 30s si no se encuentra\n",
    "                except Exception:\n",
    "                    retry_after = 40\n",
    "\n",
    "                print(f\"Rate limit exceeded. Retrying in {retry_after} seconds...\")\n",
    "                time.sleep(retry_after)\n",
    "            \n",
    "            except openai.BadRequestError as e:\n",
    "                print(f\"Prompt blocked by content filter at example {i+1}. Skipping.\")\n",
    "                respuesta = \"[FILTERED]\"\n",
    "                break  # salir del bucle, marcar como procesado con \"[FILTERED]\"\n",
    "\n",
    "\n",
    "        nuevo_id = ultimo_id + 1\n",
    "\n",
    "        # Guardar inmediatamente\n",
    "        with open(CSV_FILE, \"a\", newline='', encoding='utf-8') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=[\"id\", \"inference\"])\n",
    "            if not file_exists:\n",
    "                writer.writeheader()\n",
    "                file_exists = True\n",
    "            writer.writerow({\n",
    "                \"id\": nuevo_id,\n",
    "                \"inference\": respuesta\n",
    "            })\n",
    "\n",
    "        ultimo_id = nuevo_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5d1b947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing teleqna\n",
      "Loading dataset splits for teleqna\n",
      "Train: 724\n",
      "Val: 181\n",
      "Test: 905\n",
      "Datasets loaded and prepared.\n",
      "answering questions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses: 100%|██████████| 905/905 [00:00<00:00, 590425.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n",
      "Processing boolq\n",
      "Loading dataset splits for boolq\n",
      "Loading and preparing datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 7541\n",
      "Val: 1886\n",
      "Test: 3270\n",
      "Datasets loaded and prepared.\n",
      "answering questions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  16%|█▌        | 507/3270 [00:00<00:05, 517.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt blocked by content filter at example 507. Skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  17%|█▋        | 551/3270 [00:15<01:44, 25.97it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  19%|█▉        | 624/3270 [01:21<14:21,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  21%|██        | 683/3270 [02:22<14:31,  2.97it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  23%|██▎       | 743/3270 [03:24<13:48,  3.05it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  25%|██▍       | 803/3270 [04:26<13:40,  3.01it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  26%|██▋       | 863/3270 [05:28<13:06,  3.06it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  28%|██▊       | 923/3270 [06:30<13:07,  2.98it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  30%|███       | 983/3270 [07:33<13:17,  2.87it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  32%|███▏      | 1043/3270 [08:36<12:41,  2.93it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  34%|███▎      | 1103/3270 [09:39<11:57,  3.02it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  36%|███▌      | 1163/3270 [10:41<11:26,  3.07it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  37%|███▋      | 1223/3270 [11:43<11:24,  2.99it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  39%|███▉      | 1283/3270 [12:45<10:55,  3.03it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  41%|████      | 1343/3270 [13:47<10:51,  2.96it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  43%|████▎     | 1403/3270 [14:49<10:12,  3.05it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  45%|████▍     | 1462/3270 [15:50<09:53,  3.05it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  47%|████▋     | 1522/3270 [16:52<09:50,  2.96it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  48%|████▊     | 1581/3270 [17:53<09:07,  3.08it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  50%|█████     | 1641/3270 [18:56<09:03,  3.00it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  52%|█████▏    | 1700/3270 [19:57<09:05,  2.88it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  54%|█████▍    | 1760/3270 [20:59<08:23,  3.00it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  56%|█████▌    | 1820/3270 [22:01<08:07,  2.98it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  57%|█████▋    | 1880/3270 [23:03<07:46,  2.98it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  59%|█████▉    | 1940/3270 [24:05<08:00,  2.77it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  61%|██████    | 2000/3270 [25:07<06:56,  3.05it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  63%|██████▎   | 2060/3270 [26:10<06:35,  3.06it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  65%|██████▍   | 2120/3270 [27:12<06:26,  2.97it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  67%|██████▋   | 2180/3270 [28:14<05:58,  3.04it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  68%|██████▊   | 2239/3270 [29:15<05:46,  2.97it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  70%|███████   | 2298/3270 [30:16<05:17,  3.06it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  72%|███████▏  | 2358/3270 [31:19<05:07,  2.97it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  74%|███████▍  | 2418/3270 [32:22<05:26,  2.61it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  76%|███████▌  | 2478/3270 [33:24<04:34,  2.88it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  78%|███████▊  | 2538/3270 [34:27<04:05,  2.98it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  79%|███████▉  | 2597/3270 [35:28<03:42,  3.03it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  81%|████████▏ | 2657/3270 [36:31<03:28,  2.93it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  83%|████████▎ | 2717/3270 [37:35<03:04,  3.00it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  83%|████████▎ | 2729/3270 [38:21<05:06,  1.76it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt blocked by content filter at example 2729. Skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  85%|████████▍ | 2777/3270 [38:37<02:44,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  87%|████████▋ | 2837/3270 [39:39<02:21,  3.05it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  87%|████████▋ | 2843/3270 [40:23<17:21,  2.44s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt blocked by content filter at example 2843. Skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  89%|████████▊ | 2897/3270 [40:41<02:00,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  90%|█████████ | 2956/3270 [41:43<01:43,  3.03it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  92%|█████████▏| 3015/3270 [42:44<01:25,  2.99it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  94%|█████████▍| 3075/3270 [43:46<01:04,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  96%|█████████▌| 3135/3270 [44:49<00:45,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  98%|█████████▊| 3195/3270 [45:51<00:25,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses: 100%|█████████▉| 3255/3270 [46:53<00:05,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses: 100%|██████████| 3270/3270 [47:40<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n",
      "Processing clapnq\n",
      "Loading dataset splits for clapnq\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "668d2f65bd1242df8ae012475eebf70f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/653 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FXO0\\AppData\\Local\\miniforge3\\envs\\env_sbbd\\lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\FXO0\\.cache\\huggingface\\hub\\datasets--PrimeQA--clapnq. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5bcd9d2bde54dd5b829ebeef3e46e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "clapnq_train_answerable.jsonl:   0%|          | 0.00/6.63M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "736d91a602054281a51e6950f3e0956f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "clapnq_train_unanswerable.jsonl:   0%|          | 0.00/4.64M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fc8b26ef2754f20ba7bfadb8c747d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "clapnq_dev_answerable.jsonl:   0%|          | 0.00/986k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e901fce19e745f3856f66f68ab93cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "clapnq_dev_unanswerable.jsonl:   0%|          | 0.00/790k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04dc731cd5cd44e694c7d8fad141f723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3745 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f05feca2f98462fa60f685328a27177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 2996\n",
      "Val: 749\n",
      "Test: 600\n",
      "Datasets loaded and prepared.\n",
      "answering questions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:   8%|▊         | 45/600 [00:22<03:53,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  18%|█▊        | 105/600 [01:34<03:50,  2.15it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  28%|██▊       | 165/600 [02:42<03:06,  2.34it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  38%|███▊      | 225/600 [03:51<02:50,  2.20it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  48%|████▊     | 285/600 [05:03<02:21,  2.22it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  57%|█████▊    | 345/600 [06:12<01:38,  2.60it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  68%|██████▊   | 405/600 [07:18<01:18,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  70%|███████   | 420/600 [08:06<01:24,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt blocked by content filter at example 420. Skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  78%|███████▊  | 465/600 [08:24<00:54,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  88%|████████▊ | 525/600 [09:32<00:28,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  98%|█████████▊| 585/600 [10:37<00:07,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses: 100%|██████████| 600/600 [11:25<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n",
      "Processing covid\n",
      "Loading dataset splits for covid\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59ea9efdb228478aa0880ced05737b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.71k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FXO0\\AppData\\Local\\miniforge3\\envs\\env_sbbd\\lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\FXO0\\.cache\\huggingface\\hub\\datasets--deepset--covid_qa_deepset. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca3ca1a17d8d452aa1f8bdf0a92c2f61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/2.27M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc436a101c0453e91622a217e136e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/2019 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1292\n",
      "Val: 323\n",
      "Test: 404\n",
      "Datasets loaded and prepared.\n",
      "answering questions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  11%|█         | 45/404 [00:31<03:34,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  26%|██▌       | 105/404 [01:56<03:43,  1.34it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  41%|████      | 165/404 [03:21<02:25,  1.65it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  56%|█████▌    | 225/404 [04:43<02:55,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  71%|███████   | 285/404 [06:07<01:23,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses:  85%|████████▌ | 345/404 [07:27<00:39,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating responses: 100%|██████████| 404/404 [08:53<00:00,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = {'teleqna':40, 'boolq':3, 'clapnq':60, 'covid':120}\n",
    "for dataset_name in datasets:\n",
    "    print(f'Processing {dataset_name}')\n",
    "    CSV_FILE = f\"../results/{dataset_name}/{dataset_name}_openai.csv\"\n",
    "    train_ds, val_ds, test_ds = load_dataset_splits(dataset_name)\n",
    "    if dataset_name=='clapnq':\n",
    "        test_ds = test_ds.rename_column(\"input\", \"question\")\n",
    "    print('answering questions')\n",
    "    answer_batch(dataset_name, test_ds, CSV_FILE, datasets[dataset_name])\n",
    "    print('finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "402b1eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset splits for boolq\n",
      "Loading and preparing datasets...\n",
      "Train: 7541\n",
      "Val: 1886\n",
      "Test: 3270\n",
      "Datasets loaded and prepared.\n",
      "Results saved in: ../results/boolq/boolq_openai.csv\n"
     ]
    }
   ],
   "source": [
    "from utils.evaluate_inference import evaluate_answer\n",
    "evaluate_answer('boolq', '../results/boolq/boolq_openai.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a634360a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset splits for teleqna\n",
      "Train: 724\n",
      "Val: 181\n",
      "Test: 905\n",
      "Datasets loaded and prepared.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d1fc004e1147d5807c7076eec45b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/905 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: ../results/teleqna/teleqna_openai.csv\n"
     ]
    }
   ],
   "source": [
    "from utils.evaluate_inference import evaluate_answer\n",
    "evaluate_answer('teleqna', '../results/teleqna/teleqna_openai.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "530417b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset splits for covid\n",
      "Train: 1292\n",
      "Val: 323\n",
      "Test: 404\n",
      "Datasets loaded and prepared.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46cee5b0a28e46c09ae0989bb996a3eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/404 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: ../results/covid/covid_openai.csv\n"
     ]
    }
   ],
   "source": [
    "from utils.evaluate_inference import evaluate_answer\n",
    "evaluate_answer('covid', '../results/covid/covid_openai.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a7988a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset splits for clapnq\n",
      "Train: 2996\n",
      "Val: 749\n",
      "Test: 600\n",
      "Datasets loaded and prepared.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9209f55f9e8043ccaed98620a6b86370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved in: ../results/clapnq/clapnq_openai.csv\n"
     ]
    }
   ],
   "source": [
    "from utils.evaluate_inference import evaluate_answer\n",
    "evaluate_answer('clapnq', '../results/clapnq/clapnq_openai.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd42385",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_sbbd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
