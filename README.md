# üì° Aprimorando RAG com Modelos Leves  

Os modelos de linguagem s√£o eficazes em diversas tarefas de processamento de texto, mas enfrentam dificuldades em dom√≠nios especializados, como telecomunica√ß√µes, devido √† complexidade t√©cnica e constante evolu√ß√£o dos padr√µes. Para solucionar esse problema, este estudo aprimora um sistema de **Recupera√ß√£o e Gera√ß√£o Aumentada (RAG)** adaptado para responder perguntas sobre as especifica√ß√µes **3GPP**, um conjunto de normas fundamentais para redes m√≥veis.  

A abordagem proposta utiliza **modelos leves** para equilibrar desempenho e efici√™ncia computacional. O modelo **bge-small-en-v1.5** √© ajustado para recuperar informa√ß√µes t√©cnicas com maior precis√£o, enquanto o modelo **phi-2** passa por um fine-tuning para gerar respostas mais precisas e contextualizadas. Para otimizar esse processo, os documentos t√©cnicos s√£o segmentados estrategicamente e armazenados em um banco de dados vetorial **FAISS**, permitindo buscas eficientes. Al√©m disso, um re-ranqueador baseado no modelo **ColBERT** refina a sele√ß√£o dos documentos mais relevantes, e um √≠ndice especializado de abrevia√ß√µes do **3GPP** enriquece a compreens√£o do contexto t√©cnico.  

Os experimentos demonstraram um **aumento de 22,38% na precis√£o das respostas**, tornando a solu√ß√£o escal√°vel e vi√°vel para aplica√ß√µes reais no setor de telecomunica√ß√µes. Essa abordagem reduz os custos computacionais e possibilita a implementa√ß√£o em ambientes com recursos limitados. Como pr√≥ximos passos, a pesquisa pretende expandir a base de conhecimento e aprimorar a estrat√©gia de re-ranqueamento para continuar melhorando a precis√£o do sistema.  


![RAG Fine tuning](./paper/RAG_3gpp_FT.drawio.png)


## üìä Conjuntos de Dados Utilizados  

- **[TeleQnA](https://huggingface.co/datasets/dinho1597/3GPP-QA-MultipleChoice)** ‚Üí Conjunto com 10.000 perguntas sobre telecomunica√ß√µes, categorizadas em l√©xico, pesquisa e especifica√ß√µes 3GPP.  
- CovidQA
- CLAPnq
- BoolQ

## Fast Start

O primeiro passo √© baixar o c√≥digo do reposit√≥rio contendo os scripts necess√°rios:  
```bash
!git clone https://github.com/DinhoVCO/RAG_FT_SLM.git
```
2Ô∏è‚É£ **Instalar as depend√™ncias**
```bash
!pip install -r /RAG_FT_SLM/requirements.txt 
```

## üéØ Ajustando o Modelo de Embeddings  

Para realizar o **fine-tuning** do modelo de embeddings **bge-small-en-v1.5**, utilizamos um ambiente como **Google Colab** ou **Jupyter Notebook**. A seguir, apresentamos os passos necess√°rios para configurar e treinar o modelo.  

###  Ajuste Fino do embedding

**Executar o script de ajuste fino**
```bash
!python  ../scripts/train_embedding.py \
  --name_dataset "boolq" \
  --model_name "BAAI/bge-small-en-v1.5" \
  --new_model_name "bge-small-boolq" \
  --epochs 10 \
  --batch_size 128 \
  --output_dir "../models/boolq/embedding/"
```
üìå Nota: Voc√™ pode modificar os par√¢metros --epoch e --batch_size para ajustar o tempo de treinamento e o consumo de mem√≥ria.

## üèÜ Avalia√ß√£o do Modelo de Embeddings  

```bash
!python  ../scripts/evaluate_embedding.py \
  --name_dataset "boolq" \
  --output_dir "../results/boolq/" \
  --models_dir "../models/boolq/embedding/"
```

## Index FAISS 
```bash
!python ../scripts/create_vector_store.py \
  --dataset "boolq" \
  --emb_model "../models/boolq/embedding/bge-small-boolq_10e_128bs" \
  --cs 150 \
  --co 20 \
  --bs_emb 1024 \
  --output_dir "../vector_stores/boolq/ft_"
```

## Ajuste Fino Lora phi-2
```bash
!python  ../scripts/ft_phi.py \
  --new_model_name "phi_2_rag_k1_boolq_2e_10bs" \
  --num_epochs 2 \
  --batch_size 10 \
  --dataset_name "boolq" \
  --include_docs \
  --top_k 1 \
  --save_path "../models/boolq/adapters/" \
  --vector_store_path "../vector_stores/boolq/ft_vs_boolq_150_20"
```

## RAG Inference 

```bash
!python ../scripts/inference_rag.py \
  --lora_adapter_path "../models/boolq/adapters/best_phi_2_rag_k1_boolq_2e_10bs" \
  --max_new_tokens 10 \
  --vector_store_path "../vector_stores/boolq/ft_vs_boolq_150_20" \
  --dataset_name "boolq" \
  --output_csv_path "../results/boolq/full_ft_k10_boolq.csv" \
  --bs_emb 50 \
  --bs_gen 8 \
  --top_k 10 \
  --use_rag
```
### S√≥ phi-2

```bash
!python ../scripts/inference_rag.py \
  --gen_model "microsoft/phi-2" \
  --max_new_tokens 3 \
  --dataset_name "boolq" \
  --output_csv_path "../results/boolq/phi_k10_boolq.csv" \
  --bs_emb 10 \
  --bs_gen 10\
  --top_k 10
```

## Evaluar

```python
from utils.evaluate_inference import evaluate_answer
evaluate_answer('boolq', '../results/boolq/full_ft_k10_boolq.csv')
```
