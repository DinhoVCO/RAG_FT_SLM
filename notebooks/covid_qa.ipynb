{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28968c0e-8279-4cf8-928b-c8b3fdbda577",
   "metadata": {},
   "source": [
    "# Covid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc269e5-e694-48e5-baf5-c389e8acd6cc",
   "metadata": {},
   "source": [
    "## Create vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e844b52-0d72-4885-a0c4-87daafd07bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model embedding\n",
      "Using device: cuda\n",
      "Total number of documents: 2019\n",
      "Creating passages\n",
      "  0%|                                                  | 0/2019 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (655 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|███████████████████████████████████████| 2019/2019 [02:55<00:00, 11.48it/s]\n",
      "Total number of passages: 138891\n",
      "Removing duplicate passages\n",
      "Total number of passages created: 8397\n",
      "Creating vector store\n",
      "Generando embeddings: 100%|███████████████████████| 5/5 [00:07<00:00,  1.47s/it]\n",
      "✅ Índice FAISS creado exitosamente.\n",
      "💾 Vector store guardado en ../vector_stores/covid/base_vector_store_covid\n"
     ]
    }
   ],
   "source": [
    "!python ../scripts/create_vector_store.py \\\n",
    "  --dataset \"covid\" \\\n",
    "  --emb_model \"BAAI/bge-small-en-v1.5\" \\\n",
    "  --cs 150 \\\n",
    "  --co 20 \\\n",
    "  --bs_emb 2048 \\\n",
    "  --output_dir \"../vector_stores/covid/base_\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0063cf-e344-48df-ac7b-a4925afbe939",
   "metadata": {},
   "source": [
    "## Training Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93ec77fb-df55-4063-932c-e9170d5a0142",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdinho15971\u001b[0m (\u001b[33mdinho15971-unicamp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "Starting main process...\n",
      "Loading and preparing datasets...\n",
      "Map: 100%|█████████████████████████| 2019/2019 [00:01<00:00, 1181.24 examples/s]\n",
      "Datasets loaded and prepared.\n",
      "Creating evaluator...\n",
      "Evaluator created.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/local1/ronaldinho/projects/FinalSBBD/notebooks/wandb/run-20250427_042937-qubho8n2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbge-small-covid_10e_128bs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dinho15971-unicamp/SBBD_embeddings\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/dinho15971-unicamp/SBBD_embeddings/runs/qubho8n2\u001b[0m\n",
      "Loading model: BAAI/bge-small-en-v1.5\n",
      "Model and loss function initialized.\n",
      "Configuring training arguments...\n",
      "Training arguments configured.\n",
      "Starting training process...\n",
      "{'loss': 1.6123, 'grad_norm': 3.7695088386535645, 'learning_rate': 4.988679806432712e-05, 'epoch': 1.36}\n",
      " 14%|█████▋                                    | 15/110 [00:02<00:15,  6.19it/s]\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.6961994171142578, 'eval_telecom-ir-eval_cosine_accuracy@1': 0.7647058823529411, 'eval_telecom-ir-eval_cosine_accuracy@3': 0.8792569659442725, 'eval_telecom-ir-eval_cosine_accuracy@5': 0.9040247678018576, 'eval_telecom-ir-eval_cosine_accuracy@10': 0.9318885448916409, 'eval_telecom-ir-eval_cosine_precision@1': 0.7647058823529411, 'eval_telecom-ir-eval_cosine_recall@1': 0.7647058823529411, 'eval_telecom-ir-eval_cosine_ndcg@10': 0.8533407927217884, 'eval_telecom-ir-eval_cosine_mrr@3': 0.8178534571723427, 'eval_telecom-ir-eval_cosine_mrr@5': 0.824045407636739, 'eval_telecom-ir-eval_cosine_mrr@10': 0.8276905499041722, 'eval_telecom-ir-eval_cosine_map@100': 0.8308722175125486, 'eval_runtime': 0.5698, 'eval_samples_per_second': 566.887, 'eval_steps_per_second': 5.265, 'epoch': 1.36}\n",
      " 14%|█████▋                                    | 15/110 [00:03<00:15,  6.19it/s]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00,  5.90it/s]\u001b[A\n",
      "{'loss': 0.699, 'grad_norm': 3.121157646179199, 'learning_rate': 4.6031338320779534e-05, 'epoch': 2.73}\n",
      " 27%|███████████▍                              | 30/110 [00:05<00:12,  6.19it/s]\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.5538638830184937, 'eval_telecom-ir-eval_cosine_accuracy@1': 0.7894736842105263, 'eval_telecom-ir-eval_cosine_accuracy@3': 0.8947368421052632, 'eval_telecom-ir-eval_cosine_accuracy@5': 0.9256965944272446, 'eval_telecom-ir-eval_cosine_accuracy@10': 0.9535603715170279, 'eval_telecom-ir-eval_cosine_precision@1': 0.7894736842105263, 'eval_telecom-ir-eval_cosine_recall@1': 0.7894736842105263, 'eval_telecom-ir-eval_cosine_ndcg@10': 0.8727309934086268, 'eval_telecom-ir-eval_cosine_mrr@3': 0.8359133126934987, 'eval_telecom-ir-eval_cosine_mrr@5': 0.8428792569659442, 'eval_telecom-ir-eval_cosine_mrr@10': 0.846641112585385, 'eval_telecom-ir-eval_cosine_map@100': 0.8484394707309396, 'eval_runtime': 0.56, 'eval_samples_per_second': 576.745, 'eval_steps_per_second': 5.357, 'epoch': 2.73}\n",
      " 27%|███████████▍                              | 30/110 [00:06<00:12,  6.19it/s]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00,  6.06it/s]\u001b[A\n",
      "{'loss': 0.3927, 'grad_norm': 2.714285135269165, 'learning_rate': 3.7500000000000003e-05, 'epoch': 4.09}\n",
      " 41%|█████████████████▏                        | 45/110 [00:09<00:09,  7.16it/s]\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.4606510400772095, 'eval_telecom-ir-eval_cosine_accuracy@1': 0.8018575851393189, 'eval_telecom-ir-eval_cosine_accuracy@3': 0.9071207430340558, 'eval_telecom-ir-eval_cosine_accuracy@5': 0.9380804953560371, 'eval_telecom-ir-eval_cosine_accuracy@10': 0.9628482972136223, 'eval_telecom-ir-eval_cosine_precision@1': 0.8018575851393189, 'eval_telecom-ir-eval_cosine_recall@1': 0.8018575851393189, 'eval_telecom-ir-eval_cosine_ndcg@10': 0.8871422569748592, 'eval_telecom-ir-eval_cosine_mrr@3': 0.8513931888544891, 'eval_telecom-ir-eval_cosine_mrr@5': 0.8589783281733746, 'eval_telecom-ir-eval_cosine_mrr@10': 0.862377758120792, 'eval_telecom-ir-eval_cosine_map@100': 0.864112661621243, 'eval_runtime': 0.5604, 'eval_samples_per_second': 576.323, 'eval_steps_per_second': 5.353, 'epoch': 4.09}\n",
      " 41%|█████████████████▏                        | 45/110 [00:09<00:09,  7.16it/s]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00,  6.02it/s]\u001b[A\n",
      "{'loss': 0.2584, 'grad_norm': 1.9799833297729492, 'learning_rate': 2.6189547895593562e-05, 'epoch': 5.45}\n",
      " 55%|██████████████████████▉                   | 60/110 [00:12<00:07,  6.38it/s]\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.45718327164649963, 'eval_telecom-ir-eval_cosine_accuracy@1': 0.7956656346749226, 'eval_telecom-ir-eval_cosine_accuracy@3': 0.9009287925696594, 'eval_telecom-ir-eval_cosine_accuracy@5': 0.9411764705882353, 'eval_telecom-ir-eval_cosine_accuracy@10': 0.9690402476780186, 'eval_telecom-ir-eval_cosine_precision@1': 0.7956656346749226, 'eval_telecom-ir-eval_cosine_recall@1': 0.7956656346749226, 'eval_telecom-ir-eval_cosine_ndcg@10': 0.8855175709296688, 'eval_telecom-ir-eval_cosine_mrr@3': 0.8452012383900929, 'eval_telecom-ir-eval_cosine_mrr@5': 0.8549535603715169, 'eval_telecom-ir-eval_cosine_mrr@10': 0.8584660179861416, 'eval_telecom-ir-eval_cosine_map@100': 0.8594709174306314, 'eval_runtime': 0.5688, 'eval_samples_per_second': 567.908, 'eval_steps_per_second': 5.275, 'epoch': 5.45}\n",
      " 55%|██████████████████████▉                   | 60/110 [00:12<00:07,  6.38it/s]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00,  6.02it/s]\u001b[A\n",
      "{'loss': 0.2027, 'grad_norm': 1.9823194742202759, 'learning_rate': 1.4614624674952842e-05, 'epoch': 6.82}\n",
      " 68%|████████████████████████████▋             | 75/110 [00:15<00:05,  6.41it/s]\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.46302375197410583, 'eval_telecom-ir-eval_cosine_accuracy@1': 0.7987616099071208, 'eval_telecom-ir-eval_cosine_accuracy@3': 0.9009287925696594, 'eval_telecom-ir-eval_cosine_accuracy@5': 0.9380804953560371, 'eval_telecom-ir-eval_cosine_accuracy@10': 0.9690402476780186, 'eval_telecom-ir-eval_cosine_precision@1': 0.7987616099071208, 'eval_telecom-ir-eval_cosine_recall@1': 0.7987616099071208, 'eval_telecom-ir-eval_cosine_ndcg@10': 0.8860610497840666, 'eval_telecom-ir-eval_cosine_mrr@3': 0.8462332301341591, 'eval_telecom-ir-eval_cosine_mrr@5': 0.8552115583075334, 'eval_telecom-ir-eval_cosine_mrr@10': 0.859283011450194, 'eval_telecom-ir-eval_cosine_map@100': 0.8601647193125264, 'eval_runtime': 0.5558, 'eval_samples_per_second': 581.092, 'eval_steps_per_second': 5.397, 'epoch': 6.82}\n",
      " 68%|████████████████████████████▋             | 75/110 [00:16<00:05,  6.41it/s]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00,  6.05it/s]\u001b[A\n",
      "{'loss': 0.1598, 'grad_norm': 1.868955135345459, 'learning_rate': 5.348672631430318e-06, 'epoch': 8.18}\n",
      " 82%|██████████████████████████████████▎       | 90/110 [00:18<00:02,  7.12it/s]\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.4594588577747345, 'eval_telecom-ir-eval_cosine_accuracy@1': 0.7956656346749226, 'eval_telecom-ir-eval_cosine_accuracy@3': 0.9071207430340558, 'eval_telecom-ir-eval_cosine_accuracy@5': 0.9442724458204335, 'eval_telecom-ir-eval_cosine_accuracy@10': 0.9628482972136223, 'eval_telecom-ir-eval_cosine_precision@1': 0.7956656346749226, 'eval_telecom-ir-eval_cosine_recall@1': 0.7956656346749226, 'eval_telecom-ir-eval_cosine_ndcg@10': 0.8840065935993876, 'eval_telecom-ir-eval_cosine_mrr@3': 0.8472652218782251, 'eval_telecom-ir-eval_cosine_mrr@5': 0.8557791537667697, 'eval_telecom-ir-eval_cosine_mrr@10': 0.8581871345029238, 'eval_telecom-ir-eval_cosine_map@100': 0.859627790705998, 'eval_runtime': 0.5607, 'eval_samples_per_second': 576.054, 'eval_steps_per_second': 5.35, 'epoch': 8.18}\n",
      " 82%|██████████████████████████████████▎       | 90/110 [00:19<00:02,  7.12it/s]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00,  5.99it/s]\u001b[A\n",
      "{'loss': 0.1593, 'grad_norm': 2.0443902015686035, 'learning_rate': 4.517825684323324e-07, 'epoch': 9.55}\n",
      " 95%|███████████████████████████████████████▏ | 105/110 [00:22<00:00,  6.96it/s]\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.4614253640174866, 'eval_telecom-ir-eval_cosine_accuracy@1': 0.7956656346749226, 'eval_telecom-ir-eval_cosine_accuracy@3': 0.9071207430340558, 'eval_telecom-ir-eval_cosine_accuracy@5': 0.9411764705882353, 'eval_telecom-ir-eval_cosine_accuracy@10': 0.9628482972136223, 'eval_telecom-ir-eval_cosine_precision@1': 0.7956656346749226, 'eval_telecom-ir-eval_cosine_recall@1': 0.7956656346749226, 'eval_telecom-ir-eval_cosine_ndcg@10': 0.8839117155185006, 'eval_telecom-ir-eval_cosine_mrr@3': 0.8472652218782252, 'eval_telecom-ir-eval_cosine_mrr@5': 0.8551599587203303, 'eval_telecom-ir-eval_cosine_mrr@10': 0.8580839353285173, 'eval_telecom-ir-eval_cosine_map@100': 0.8594854549820987, 'eval_runtime': 0.5521, 'eval_samples_per_second': 585.074, 'eval_steps_per_second': 5.434, 'epoch': 9.55}\n",
      " 95%|███████████████████████████████████████▏ | 105/110 [00:22<00:00,  6.96it/s]\n",
      "100%|█████████████████████████████████████████████| 3/3 [00:00<00:00,  6.09it/s]\u001b[A\n",
      "{'train_runtime': 24.5585, 'train_samples_per_second': 526.092, 'train_steps_per_second': 4.479, 'train_loss': 0.48194903297857805, 'epoch': 10.0}\n",
      "100%|█████████████████████████████████████████| 110/110 [00:24<00:00,  4.47it/s]\n",
      "Training completed.\n",
      "Saving the trained model...\n",
      "Model saved successfully.\n",
      "Process completed successfully.\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mbge-small-covid_10e_128bs\u001b[0m at: \u001b[34mhttps://wandb.ai/dinho15971-unicamp/SBBD_embeddings/runs/qubho8n2\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250427_042937-qubho8n2/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python  ../scripts/train_embedding.py \\\n",
    "  --name_dataset \"covid\" \\\n",
    "  --model_name \"BAAI/bge-small-en-v1.5\" \\\n",
    "  --new_model_name \"bge-small-covid\" \\\n",
    "  --epochs 10 \\\n",
    "  --batch_size 128 \\\n",
    "  --output_dir \"../models/covid/embedding/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c01d24-d665-40e8-a583-e82a93fbd886",
   "metadata": {},
   "source": [
    "## Evaluate Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceebf859-3239-434a-b31a-05ab54119e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando modelos...\n",
      "Models loaded\n",
      "Loading datasets...\n",
      "Loading and preparing datasets...\n",
      "Datasets loaded and prepared.\n",
      "Loaded dataset\n",
      "Creating evaluator...\n",
      "Evaluator created.\n",
      "Evaluating models\n",
      "Save results...\n"
     ]
    }
   ],
   "source": [
    "!python  ../scripts/evaluate_embedding.py \\\n",
    "  --name_dataset \"covid\" \\\n",
    "  --output_dir \"../results/covid/\" \\\n",
    "  --models_dir \"../models/covid/embedding/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6aff68-7411-440a-a89d-cd017249721e",
   "metadata": {},
   "source": [
    "## Create new vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c6b0bc5-7b5a-4f6c-b4ae-d64e8162690b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model embedding\n",
      "Using device: cuda\n",
      "Total number of documents: 2019\n",
      "Creating passages\n",
      "  0%|                                                  | 0/2019 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (655 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|███████████████████████████████████████| 2019/2019 [02:56<00:00, 11.43it/s]\n",
      "Total number of passages: 138891\n",
      "Removing duplicate passages\n",
      "Total number of passages created: 8397\n",
      "Creating vector store\n",
      "Generando embeddings: 100%|███████████████████████| 5/5 [00:07<00:00,  1.50s/it]\n",
      "✅ Índice FAISS creado exitosamente.\n",
      "💾 Vector store guardado en ../vector_stores/covid/ft_vector_store_covid\n"
     ]
    }
   ],
   "source": [
    "!python ../scripts/create_vector_store.py \\\n",
    "  --dataset \"covid\" \\\n",
    "  --emb_model \"../models/covid/embedding/bge-small-covid_10e_128bs\" \\\n",
    "  --cs 150 \\\n",
    "  --co 20 \\\n",
    "  --bs_emb 2048 \\\n",
    "  --output_dir \"../vector_stores/covid/ft_\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0205f7-3530-4249-8ec1-1bc8d2108b23",
   "metadata": {},
   "source": [
    "## Train Phi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79c6b975-6f7c-4298-a237-114669a9e81b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdinho15971\u001b[0m (\u001b[33mdinho15971-unicamp\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/local1/ronaldinho/projects/solving_problems/test_sbbd/notebooks/wandb/run-20250430_141551-hztkhe4b\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mphi-2-rag-k1_covid-5e_10bs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/dinho15971-unicamp/SBBD_phi-2-adapters\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/dinho15971-unicamp/SBBD_phi-2-adapters/runs/hztkhe4b\u001b[0m\n",
      "Usando dispositivo: cuda\n",
      "💾  Vector store cargado desde ../vector_stores/covid/base_vector_store_covid\n",
      "Generating dataset\n",
      "Using k = 3 passages\n",
      "Loading and preparing datasets...\n",
      "Train: 1292\n",
      "Val: 323\n",
      "Test: 404\n",
      "Datasets loaded and prepared.\n",
      "Creating dataset for covid\n",
      "🔍 Buscando: 100%|████████████████████████████| 162/162 [00:01<00:00, 81.61it/s]\n",
      "Map: 100%|█████████████████████████| 1292/1292 [00:00<00:00, 4760.08 examples/s]\n",
      "Example\n",
      "Instruct:  Using the information in the context, answer the question as concisely and faithfully as possible.If the context does not provide enough information to answer confidently, answer based on the most likely interpretation from the given text.\n",
      "\n",
      "Context:\n",
      "\n",
      "Document 0:066 (618 of them are in Wuhan) confirmed cases and 56 (45 of them were in Wuhan) deaths in mainland China [4] , and sporadic cases exported from Wuhan were reported in Thailand, Japan, Republic of Korea, Hong Kong, Taiwan, Australia, and the United States, please see the World Health Organization (W\n",
      "Document 1:The first three cases detected were reported in France on 24 January 2020 and had onset of symptoms on 17, 19 and 23 January respectively [10] . The first death was reported on 15 February in France. As at 21 February, nine countries had reported cases ( Figure) : Belgium (1), Finland (1), France (12), Germany (16), Italy (3), Russia (2), Spain (2), Sweden (1) and the UK (9 -not included further).\n",
      "Document 2:As of 24 January 2020, the cumulative incidence in China is 830 cases, of which 549 cases were diagnosed in Hubei, 26 in Beijing, 20 in Shanghai, and 53 in Guangdong. Additionally, twenty-six deaths have been linked to the outbreak [6, 8] , and thirteen cases were exported to Japan, Singapore, South Korea, Taiwan, Thailand, Vietnam and the United States as of 22 January 2020. Considering that enhanced surveillance has been underway in these importing countries, case ascertainment has been perhaps better in exported case data.\n",
      "Document 3:We suspected that there was a number of cases, denoted by ξ, under-reported from 1 to 15 January 2020. The cumulative total number of cases, denoted by C i , of the i-th day since 1 December 2019 is the summation of the cumulative reported, c i , and cumulative unreported cases, Ξ i . We have C i = c i + Ξ i , where c i is observed from the data, and Ξ i is 0 for i before 1 January and ξ for i after 15 January 2020. Following previous studies [11, 12] , we modelled the epidemic curve, i.e., the C i series, as an exponential growing Poisson process\n",
      "\n",
      "Question:\n",
      "As of 26 January 2020, what countries had sporadic cases?\n",
      "\n",
      "Output:\n",
      "were reported in Thailand, Japan, Republic of Korea, Hong Kong, Taiwan, Australia, and\n",
      "Loading model\n",
      "Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]^C\n"
     ]
    }
   ],
   "source": [
    "!python  ../scripts/ft_phi.py \\\n",
    "  --new_model_name \"phi-2-rag-k1_covid-5e_10bs\" \\\n",
    "  --num_epochs 5 \\\n",
    "  --batch_size 10 \\\n",
    "  --dataset_name \"covid\" \\\n",
    "  --include_docs \\\n",
    "  --top_k 3 \\\n",
    "  --save_path \"../models/covid/adapters/\" \\\n",
    "  --vector_store_path \"../vector_stores/covid/base_vector_store_covid\" \\\n",
    "  --emb_model \"BAAI/bge-small-en-v1.5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6580f3d-dc58-4394-be67-fc8b68a431a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (env_2)",
   "language": "python",
   "name": "env_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
